################################################################ Group members: ###############################################################################
# Mohanapriya Narapareddy  	- 	 mxn160330
# Sangeeta Kadambala 		-	 sxk160731
#
################################################################ How to execute the code ######################################################################
# Code is run on databricks, for preprocessing we used PySpark and for Classifier we used Scala
# We need to import 2 jars spark-xml_2.11-0.3.5.jar and spark-utils_2.11-0.1.jar for the code to run which can be downloaded through Maven repository
# We created an Apache Spark 2.2.0, Scala 2.11 6GB cluster in Databricks
# 2 Notebooks one for preprocessing (Python Notebook) and one for Classification (Scala Notebook)
# Execute each commands that are mentioned below in each notebook to run. Once preprocessing is done the result is stored as csv format and uploaded into other
# notebook for classification
################################################################ Preprocessing of data ########################################################################
# start of preprocessing steps:	
from pyspark.sql import SQLContext
from pyspark.sql.types import *

coodinates = StructType([ \
  StructField("xCoord", DoubleType(), True), \
  StructField("yCoord", DoubleType(), True)])

roi = StructType([ \
    StructField("inclusion", BooleanType(), True), \
    StructField("edgeMap", ArrayType(coodinates) , True)])
characteristics = StructType([ \
    StructField("subtlety", DoubleType(), True), \
    StructField("confidence", DoubleType(), True), \
    StructField("malignancy", IntegerType(), True), \
    StructField("margin", IntegerType(), True), \
    StructField("sphericity", IntegerType(), True) \
    ])
                        
nodule = StructType([ \
    StructField("noduleID", LongType(), True), \
    StructField("characteristics", characteristics, True), \
    StructField("roi", roi, True)])

characteristicsExtra = StructType([ \
    StructField("subtlety", DoubleType(), True), \
    StructField("confidence", DoubleType(), True), \
    StructField("malignancy", IntegerType(), True), \
    StructField("margin", IntegerType(), True), \
    StructField("sphericity", IntegerType(), True) \
    ])
                        
noduleExtra = StructType([ \
    StructField("noduleID", LongType(), True), \
    StructField("characteristics", characteristicsExtra, True), \
    StructField("roi", roi, True)])



df = sqlContext.read.format('com.databricks.spark.xml').options(rowTag="unblindedReadNodule").load('/FileStore/tables/{185,157,186,187,188,189}/*.xml', schema = nodule)
dfExtra = sqlContext.read.format('com.databricks.spark.xml').options(rowTag="unblindedRead").load('/FileStore/tables/{185,157,186,187,188,189}/*.xml', schema = noduleExtra)
finalDF = df.unionAll(dfExtra)

dfNew = finalDF.select("noduleID","characteristics.*","roi")

import re

def calcArea(arrString):
    val =  re.sub('[^0-9,.()]', '', arrString).lstrip('(').rstrip(')').lstrip('[').rstrip(']').split("),(")
    if(len(val)==1):
      return 1.0
    else:
      n = len(val)
      a = 0.0
      for i in range(n):
        j = (i + 1) % n
        a += abs(float(val[i].split(",")[0]) * float(val[j].split(",")[1])-float(val[j].split(",")[0]) * float(val[i].split(",")[1]))
      return a/2.0
	  
noduleRDD = dfNew.na.fill(0).rdd
noduleDataDf = noduleRDD.map(lambda x : (x[0],x[1],x[2],x[3],x[4],x[5],x[6][0],calcArea(str(x[6][1])))).toDF()

sqlContext.registerDataFrameAsTable(noduleDataDf, "noduleData")

noduleDataLbDF = sqlContext.sql("select _1 as noduleID, _2 as subtlety, _3 as confidence, _6 as sphericity, _5 as margin, _4 as malignancy, case when _7 = 'true' then 1 when _7 = 'false' then 0 end as inclusion, _8 as area from noduleData")
noduleDataLbDF.na.fill(0)
display(noduleDataLbDF)


################################################# Machine Learning classification and the respective code is below: ###########################################

import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.classification.{RandomForestClassificationModel, RandomForestClassifier}
import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
import org.apache.spark.ml.classification.LinearSVC
import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD}
import org.apache.spark.ml.feature.PCA
import org.apache.spark.ml.linalg.Vector
import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}
import org.apache.spark.sql.functions.col
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator

val patientData = sc.textFile("/FileStore/tables/PreprocessedData.csv")

case class patients(label:Double, features:Vector)

val patientDataDf = patientData.map({ line => val x = line.split(',')
  patients(x(6).toDouble, Vectors.dense(x(1).toDouble, x(2).toDouble, x(3).toDouble, x(4).toDouble, x(5).toDouble,  x(7).toDouble))
    }).toDF()
	
val splits = patientDataDf.randomSplit(Array(0.8, 0.2), seed = 11L)
val trainingData = splits(0)
val testData = splits(1)

###################################################################### SVM Classifier #########################################################################
import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}
import org.apache.spark.ml.classification.LinearSVC


val svm = new LinearSVC().setRegParam(0.2)


val pipeline = new Pipeline()
  .setStages(Array(svm))

val paramGrid = new ParamGridBuilder()
      .addGrid(svm.maxIter, Array(10,100,150,200))
      .build()


val evaluator = new BinaryClassificationEvaluator

val cv = new CrossValidator()
  .setEstimator(pipeline)
  .setEvaluator(evaluator)
  .setEstimatorParamMaps(paramGrid)
  .setNumFolds(5)

val cvModel = cv.fit(trainingData)
val predictions = cvModel.transform(testData)

// predictions
val predictions = cvModel.transform(testData)
val accuracy = evaluator.evaluate(predictions)

val pl = predictions.rdd.map(x => (x(3).toString().toDouble, x(0).toString().toDouble))
val metrics1 = new MulticlassMetrics(pl)
println("Confusion matrix:")
println(metrics1.confusionMatrix)
val accuracy1 = metrics1.accuracy
println(s"Accuracy = $accuracy1")
val labels = metrics1.labels
labels.foreach { l =>
  println(s"Precision($l) = " + metrics1.precision(l))
}
labels.foreach { l =>
  println(s"Recall($l) = " + metrics1.recall(l))
}
labels.foreach { l =>
  println(s"FPR($l) = " + metrics1.falsePositiveRate(l))
}
labels.foreach { l =>
  println(s"F1-Score($l) = " + metrics1.fMeasure(l))
}

println(s"Weighted precision: ${metrics1.weightedPrecision}")
println(s"Weighted recall: ${metrics1.weightedRecall}")
println(s"Weighted F1 score: ${metrics1.weightedFMeasure}")

###################################################################### SVM Classifier with PCA ################################################################
val PCA = new PCA().setInputCol("features").setK(5).fit(patientDataDf).setOutputCol("intermediatefeatures")
val pcaData = PCA.transform(patientDataDf)
val pcaDF = pcaData.drop(pcaData.col("features"))

val lIndexer = new StringIndexer().setInputCol("label").setOutputCol("indexedLabel").fit(pcaDF)
val fIndexer = new VectorIndexer().setInputCol("intermediatefeatures").setOutputCol("indexedFeatures").setMaxCategories(4).fit(pcaDF)
val splits = pcaDF.randomSplit(Array(0.8, 0.2), seed = 11L)
val trainingData = splits(0)
val testData = splits(1)
trainingData.take(10)
val rf = new LinearSVC().setRegParam(0.2).setLabelCol("indexedLabel").setFeaturesCol("indexedFeatures")// vary reg param and max iter based on above results
val label_converter = new IndexToString().setInputCol("prediction").setOutputCol("predictedLabel").setLabels(lIndexer.labels)
val pipeline = new Pipeline().setStages(Array(lIndexer, fIndexer, rf, label_converter))
val pipeline_model = pipeline.fit(trainingData)
val predictions = pipeline_model.transform(testData)
val evaluator = new MulticlassClassificationEvaluator().setLabelCol("indexedLabel").setPredictionCol("prediction").setMetricName("accuracy")
val accuracy = evaluator.evaluate(predictions)

display(predictions)

###################################################################### Random Forest Classifier ###############################################################
val splits = patientDataDf.randomSplit(Array(0.8, 0.2), seed = 11L)
val trainingData = splits(0)
val testData = splits(1)
val rf = new RandomForestClassifier()
val pipeline = new Pipeline()
  .setStages(Array(rf))

val paramGrid = new ParamGridBuilder()
  .addGrid(rf.maxBins, Array(100,500,200,50))
  .addGrid(rf.minInstancesPerNode, Array(2,5,10))
  .build()


val evaluator = new BinaryClassificationEvaluator

val cv = new CrossValidator()
  .setEstimator(pipeline)
  .setEvaluator(evaluator)
  .setEstimatorParamMaps(paramGrid)
  .setNumFolds(5)

val cvModel = cv.fit(trainingData)

val predictions = cvModel.transform(testData)
val accuracy = evaluator.evaluate(predictions)

val pl = predictions.rdd.map(x => (x(4).toString().toDouble, x(0).toString().toDouble))
val metrics1 = new MulticlassMetrics(pl)
println("Confusion matrix:")
println(metrics1.confusionMatrix)
val accuracy1 = metrics1.accuracy
println(s"Accuracy = $accuracy1")
val labels = metrics1.labels
labels.foreach { l =>
  println(s"Precision($l) = " + metrics1.precision(l))
}
labels.foreach { l =>
  println(s"Recall($l) = " + metrics1.recall(l))
}
labels.foreach { l =>
  println(s"FPR($l) = " + metrics1.falsePositiveRate(l))
}
labels.foreach { l =>
  println(s"F1-Score($l) = " + metrics1.fMeasure(l))
}

println(s"Weighted precision: ${metrics1.weightedPrecision}")
println(s"Weighted recall: ${metrics1.weightedRecall}")
println(s"Weighted F1 score: ${metrics1.weightedFMeasure}")

display(predictions.select("label","prediction"))

###################################################################### Random Forest Classifier with PCA ######################################################
val PCA = new PCA().setInputCol("features").setK(6).fit(patientDataDf).setOutputCol("intermediatefeatures")
val pcaData = PCA.transform(patientDataDf)
val pcaDF = pcaData.drop(pcaData.col("features"))

val lIndexer = new StringIndexer().setInputCol("label").setOutputCol("indexedLabel").fit(pcaDF)
val fIndexer = new VectorIndexer().setInputCol("intermediatefeatures").setOutputCol("indexedFeatures").setMaxCategories(4).fit(pcaDF)
val splits = pcaDF.randomSplit(Array(0.8, 0.2), seed = 11L)
val trainingData = splits(0)
val testData = splits(1)
trainingData.take(10)
val rf = new RandomForestClassifier().setLabelCol("indexedLabel").setFeaturesCol("indexedFeatures").setNumTrees(30)
val label_converter = new IndexToString().setInputCol("prediction").setOutputCol("predictedLabel").setLabels(lIndexer.labels)
val pipeline = new Pipeline().setStages(Array(lIndexer, fIndexer, rf, label_converter))
val pipeline_model = pipeline.fit(trainingData)
val predictions = pipeline_model.transform(testData)
val evaluator = new MulticlassClassificationEvaluator().setLabelCol("indexedLabel").setPredictionCol("prediction").setMetricName("accuracy")
val accuracy = evaluator.evaluate(predictions)

val pl = predictions.rdd.map(x => (x(7).toString().toDouble, x(0).toString().toDouble))
val metrics1 = new MulticlassMetrics(pl)
println("Confusion matrix:")
println(metrics1.confusionMatrix)
val accuracy = metrics1.accuracy
println(s"Accuracy = $accuracy")
val labels = metrics1.labels
labels.foreach { l =>
  println(s"Precision($l) = " + metrics1.precision(l))
}
labels.foreach { l =>
  println(s"Recall($l) = " + metrics1.recall(l))
}
labels.foreach { l =>
  println(s"FPR($l) = " + metrics1.falsePositiveRate(l))
}
labels.foreach { l =>
  println(s"F1-Score($l) = " + metrics1.fMeasure(l))
}

println(s"Weighted precision: ${metrics1.weightedPrecision}")
println(s"Weighted recall: ${metrics1.weightedRecall}")
println(s"Weighted F1 score: ${metrics1.weightedFMeasure}")